## Updated on 2025.11.21
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#process-reward>Process Reward</a></li>
    <li><a href=#llm-reasoning>LLM Reasoning</a></li>
  </ol>
</details>

## Process Reward

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-11-20**|**EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards**|Omkat Thawakar et.al.|[2511.16672](http://arxiv.org/abs/2511.16672)|null|
|**2025-11-20**|**Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation**|Ziyu Guo et.al.|[2511.16671](http://arxiv.org/abs/2511.16671)|null|
|**2025-11-20**|**Learning to Think Fast and Slow for Visual Language Models**|Chenyu Lin et.al.|[2511.16670](http://arxiv.org/abs/2511.16670)|null|
|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Junhao Cheng et.al.|[2511.16669](http://arxiv.org/abs/2511.16669)|null|
|**2025-11-20**|**SceneDesigner: Controllable Multi-Object Image Generation with 9-DoF Pose Manipulation**|Zhenyuan Qin et.al.|[2511.16666](http://arxiv.org/abs/2511.16666)|null|
|**2025-11-20**|**Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies**|Zohar Rimon et.al.|[2511.16596](http://arxiv.org/abs/2511.16596)|null|
|**2025-11-20**|**gfnx: Fast and Scalable Library for Generative Flow Networks in JAX**|Daniil Tiapkin et.al.|[2511.16592](http://arxiv.org/abs/2511.16592)|null|
|**2025-11-20**|**Large Language Model-Based Reward Design for Deep Reinforcement Learning-Driven Autonomous Cyber Defense**|Sayak Mukherjee et.al.|[2511.16483](http://arxiv.org/abs/2511.16483)|null|
|**2025-11-20**|**A Comparison Between Decision Transformers and Traditional Offline Reinforcement Learning Algorithms**|Ali Murtaza Caunhye et.al.|[2511.16475](http://arxiv.org/abs/2511.16475)|null|
|**2025-11-20**|**OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe**|Kaichen Zhang et.al.|[2511.16334](http://arxiv.org/abs/2511.16334)|null|
|**2025-11-20**|**Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement**|Jiashu Yao et.al.|[2511.16331](http://arxiv.org/abs/2511.16331)|null|
|**2025-11-20**|**Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning**|Shreyas Kumar et.al.|[2511.16330](http://arxiv.org/abs/2511.16330)|null|
|**2025-11-20**|**Weakly Supervised Segmentation and Classification of Alpha-Synuclein Aggregates in Brightfield Midbrain Images**|Erwan Dereure et.al.|[2511.16268](http://arxiv.org/abs/2511.16268)|null|
|**2025-11-20**|**Prediction of atomic H adsorption energies in metalloid doped MSSe (M = Mo/W) Janus layers: A combined DFT and machine learning study**|G. Tejaswini et.al.|[2511.16263](http://arxiv.org/abs/2511.16263)|null|
|**2025-11-20**|**Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob**|Yun Lu et.al.|[2511.16248](http://arxiv.org/abs/2511.16248)|null|
|**2025-11-20**|**FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks**|Zhen Hao Wong et.al.|[2511.16216](http://arxiv.org/abs/2511.16216)|null|
|**2025-11-20**|**Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning**|Pei Yang et.al.|[2511.16202](http://arxiv.org/abs/2511.16202)|null|
|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Zeting Liu et.al.|[2511.16166](http://arxiv.org/abs/2511.16166)|null|
|**2025-11-20**|**Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints**|Yongnan Jin et.al.|[2511.16139](http://arxiv.org/abs/2511.16139)|null|
|**2025-11-20**|**Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models**|Yijun Yang et.al.|[2511.16110](http://arxiv.org/abs/2511.16110)|null|
|**2025-11-20**|**A Mathematical Framework for Custom Reward Functions in Job Application Evaluation using Reinforcement Learning**|Shreyansh Jain et.al.|[2511.16073](http://arxiv.org/abs/2511.16073)|null|
|**2025-11-20**|**Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers**|Takeru Tsunoori et.al.|[2511.16050](http://arxiv.org/abs/2511.16050)|null|
|**2025-11-20**|**Physics Informed Multi-task Joint Generative Learning for Arterial Vehicle Trajectory Reconstruction Considering Lane Changing Behavior**|Mengyun Xu et.al.|[2511.16019](http://arxiv.org/abs/2511.16019)|null|
|**2025-11-20**|**CARE: Turning LLMs Into Causal Reasoning Expert**|Juncheng Dong et.al.|[2511.16016](http://arxiv.org/abs/2511.16016)|null|
|**2025-11-19**|**Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs**|Chelsea Zou et.al.|[2511.15921](http://arxiv.org/abs/2511.15921)|null|
|**2025-11-19**|**Writing With Machines and Peers: Designing for Critical Engagement with Generative AI**|Xinran Zhu et.al.|[2511.15750](http://arxiv.org/abs/2511.15750)|null|
|**2025-11-19**|**GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization**|Yikun Wang et.al.|[2511.15705](http://arxiv.org/abs/2511.15705)|null|
|**2025-11-19**|**The Impact of Quantization on Large Reasoning Model Reinforcement Learning**|Medha Kumar et.al.|[2511.15694](http://arxiv.org/abs/2511.15694)|null|
|**2025-11-20**|**VisPlay: Self-Evolving Vision-Language Models from Images**|Yicheng He et.al.|[2511.15661](http://arxiv.org/abs/2511.15661)|null|
|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei et.al.|[2511.15605](http://arxiv.org/abs/2511.15605)|null|
|**2025-11-19**|**DEPO: Dual-Efficiency Preference Optimization for LLM Agents**|Sirui Chen et.al.|[2511.15392](http://arxiv.org/abs/2511.15392)|null|
|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Yunjiao Zhou et.al.|[2511.15379](http://arxiv.org/abs/2511.15379)|null|
|**2025-11-19**|**ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing**|Liangyu Chen et.al.|[2511.15266](http://arxiv.org/abs/2511.15266)|null|
|**2025-11-19**|**GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning**|Yanchen Xu et.al.|[2511.15256](http://arxiv.org/abs/2511.15256)|null|
|**2025-11-19**|**Reasoning in Diffusion Large Language Models is Concentrated in Dynamic Confusion Zones**|Ranfei Chen et.al.|[2511.15208](http://arxiv.org/abs/2511.15208)|null|
|**2025-11-19**|**Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning**|Yuxuan Gu et.al.|[2511.15190](http://arxiv.org/abs/2511.15190)|null|
|**2025-11-19**|**Multimodal Wireless Foundation Models**|Ahmed Aboulfotouh et.al.|[2511.15162](http://arxiv.org/abs/2511.15162)|null|
|**2025-11-19**|**TiCAL:Typicality-Based Consistency-Aware Learning for Multimodal Emotion Recognition**|Wen Yin et.al.|[2511.15085](http://arxiv.org/abs/2511.15085)|null|
|**2025-11-20**|**Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation**|Vladimir Arkhipkin et.al.|[2511.14993](http://arxiv.org/abs/2511.14993)|null|
|**2025-11-18**|**Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization**|Yifeng Ding et.al.|[2511.14846](http://arxiv.org/abs/2511.14846)|null|
|**2025-11-18**|**UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning**|Rui Tian et.al.|[2511.14760](http://arxiv.org/abs/2511.14760)|null|
|**2025-11-18**|**Vision Large Language Models Are Good Noise Handlers in Engagement Analysis**|Alexander Vedernikov et.al.|[2511.14749](http://arxiv.org/abs/2511.14749)|null|
|**2025-11-18**|**SMRC: Aligning Large Language Models with Student Reasoning for Mathematical Error Correction**|Biaojie Zeng et.al.|[2511.14684](http://arxiv.org/abs/2511.14684)|null|
|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al.|[2511.14659](http://arxiv.org/abs/2511.14659)|null|
|**2025-11-18**|**Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language**|Minyoung Hwang et.al.|[2511.14565](http://arxiv.org/abs/2511.14565)|null|
|**2025-11-18**|**Audio Question Answering with GRPO-Based Fine-Tuning and Calibrated Segment-Level Predictions**|Marcel Gibier et.al.|[2511.14307](http://arxiv.org/abs/2511.14307)|null|
|**2025-11-18**|**Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation**|Weimin Bai et.al.|[2511.14271](http://arxiv.org/abs/2511.14271)|null|
|**2025-11-18**|**Object-Centric World Models for Causality-Aware Reinforcement Learning**|Yosuke Nishimoto et.al.|[2511.14262](http://arxiv.org/abs/2511.14262)|null|
|**2025-11-18**|**Enhancing Generalization of Depth Estimation Foundation Model via Weakly-Supervised Adaptation with Regularization**|Yan Huang et.al.|[2511.14238](http://arxiv.org/abs/2511.14238)|null|
|**2025-11-18**|**LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation**|Hao Jiang et.al.|[2511.14221](http://arxiv.org/abs/2511.14221)|null|

<p align=right>(<a href=#updated-on-20251121>back to top</a>)</p>

## LLM Reasoning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-11-20**|**EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards**|Omkat Thawakar et.al.|[2511.16672](http://arxiv.org/abs/2511.16672)|null|
|**2025-11-20**|**Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation**|Ziyu Guo et.al.|[2511.16671](http://arxiv.org/abs/2511.16671)|null|
|**2025-11-20**|**Learning to Think Fast and Slow for Visual Language Models**|Chenyu Lin et.al.|[2511.16670](http://arxiv.org/abs/2511.16670)|null|
|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Junhao Cheng et.al.|[2511.16669](http://arxiv.org/abs/2511.16669)|null|
|**2025-11-20**|**Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter**|Qinghao Hu et.al.|[2511.16665](http://arxiv.org/abs/2511.16665)|null|
|**2025-11-20**|**Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs**|Ali Taghibakhshi et.al.|[2511.16664](http://arxiv.org/abs/2511.16664)|null|
|**2025-11-20**|**Cognitive Foundations for Reasoning and Their Manifestation in LLMs**|Priyanka Kargupta et.al.|[2511.16660](http://arxiv.org/abs/2511.16660)|null|
|**2025-11-20**|**Evolution Strategies at the Hyperscale**|Bidipta Sarkar et.al.|[2511.16652](http://arxiv.org/abs/2511.16652)|null|
|**2025-11-20**|**SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction**|Guolin Huang et.al.|[2511.16635](http://arxiv.org/abs/2511.16635)|null|
|**2025-11-20**|**StreetView-Waste: A Multi-Task Dataset for Urban Waste Management**|Diogo J. Paulo et.al.|[2511.16440](http://arxiv.org/abs/2511.16440)|null|
|**2025-11-20**|**ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports**|Sherine George et.al.|[2511.16438](http://arxiv.org/abs/2511.16438)|null|
|**2025-11-20**|**OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe**|Kaichen Zhang et.al.|[2511.16334](http://arxiv.org/abs/2511.16334)|null|
|**2025-11-20**|**Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning**|Mohammad Areeb Qazi et.al.|[2511.16333](http://arxiv.org/abs/2511.16333)|null|
|**2025-11-20**|**Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement**|Jiashu Yao et.al.|[2511.16331](http://arxiv.org/abs/2511.16331)|null|
|**2025-11-20**|**MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering**|Zhiyuan Li et.al.|[2511.16283](http://arxiv.org/abs/2511.16283)|null|
|**2025-11-20**|**How Robot Dogs See the Unseeable**|Oliver Bimber et.al.|[2511.16262](http://arxiv.org/abs/2511.16262)|null|
|**2025-11-20**|**Pass@k Metric for RLVR: A Diagnostic Tool of Exploration, But Not an Objective**|Yang Yu et.al.|[2511.16231](http://arxiv.org/abs/2511.16231)|null|
|**2025-11-20**|**Q-MLLM: Vector Quantization for Robust Multimodal Large Language Model Security**|Wei Zhao et.al.|[2511.16229](http://arxiv.org/abs/2511.16229)|null|
|**2025-11-20**|**Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions**|Caixin Kang et.al.|[2511.16221](http://arxiv.org/abs/2511.16221)|null|
|**2025-11-20**|**FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks**|Zhen Hao Wong et.al.|[2511.16216](http://arxiv.org/abs/2511.16216)|null|
|**2025-11-20**|**ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025**|Xu Qiang et.al.|[2511.16205](http://arxiv.org/abs/2511.16205)|null|
|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan et.al.|[2511.16203](http://arxiv.org/abs/2511.16203)|null|
|**2025-11-20**|**Video2Layout: Recall and Reconstruct Metric-Grounded Cognitive Map for Spatial Reasoning**|Yibin Huang et.al.|[2511.16160](http://arxiv.org/abs/2511.16160)|null|
|**2025-11-20**|**Reasoning Guided Embeddings: Leveraging MLLM Reasoning for Improved Multimodal Retrieval**|Chunxu Liu et.al.|[2511.16150](http://arxiv.org/abs/2511.16150)|null|
|**2025-11-20**|**Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints**|Yongnan Jin et.al.|[2511.16139](http://arxiv.org/abs/2511.16139)|null|
|**2025-11-20**|**T2T-VICL: Unlocking the Boundaries of Cross-Task Visual In-Context Learning via Implicit Text-Driven VLMs**|Shao-Jun Xia et.al.|[2511.16107](http://arxiv.org/abs/2511.16107)|null|
|**2025-11-20**|**Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning**|Peng Xia et.al.|[2511.16043](http://arxiv.org/abs/2511.16043)|null|
|**2025-11-20**|**Liars' Bench: Evaluating Lie Detectors for Language Models**|Kieron Kretschmar et.al.|[2511.16035](http://arxiv.org/abs/2511.16035)|null|
|**2025-11-20**|**CARE: Turning LLMs Into Causal Reasoning Expert**|Juncheng Dong et.al.|[2511.16016](http://arxiv.org/abs/2511.16016)|null|
|**2025-11-20**|**MUSEKG: A Knowledge Graph Over Museum Collections**|Jinhao Li et.al.|[2511.16014](http://arxiv.org/abs/2511.16014)|null|
|**2025-11-20**|**InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution**|Qingao Dong et.al.|[2511.16005](http://arxiv.org/abs/2511.16005)|null|
|**2025-11-20**|**CARE-RAG - Clinical Assessment and Reasoning in RAG**|Deepthi Potluri et.al.|[2511.15994](http://arxiv.org/abs/2511.15994)|null|
|**2025-11-20**|**Fairness in Multi-modal Medical Diagnosis with Demonstration Selection**|Dawei Li et.al.|[2511.15986](http://arxiv.org/abs/2511.15986)|null|
|**2025-11-20**|**KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy**|Zhe Li et.al.|[2511.15974](http://arxiv.org/abs/2511.15974)|null|
|**2025-11-20**|**JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation**|Zhenyu Bi et.al.|[2511.15958](http://arxiv.org/abs/2511.15958)|null|
|**2025-11-19**|**RB-FT: Rationale-Bootstrapped Fine-Tuning for Video Classification**|Meilong Xu et.al.|[2511.15923](http://arxiv.org/abs/2511.15923)|null|
|**2025-11-19**|**Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs**|Chelsea Zou et.al.|[2511.15921](http://arxiv.org/abs/2511.15921)|null|
|**2025-11-19**|**Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs**|Ivan Chulo et.al.|[2511.15895](http://arxiv.org/abs/2511.15895)|null|
|**2025-11-19**|**What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning**|Jeremias Ferrao et.al.|[2511.15886](http://arxiv.org/abs/2511.15886)|null|
|**2025-11-19**|**Step-Audio-R1 Technical Report**|Fei Tian et.al.|[2511.15848](http://arxiv.org/abs/2511.15848)|null|
|**2025-11-19**|**Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions**|St√©phane Aroca-Ouellette et.al.|[2511.15830](http://arxiv.org/abs/2511.15830)|null|
|**2025-11-19**|**GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization**|Yikun Wang et.al.|[2511.15705](http://arxiv.org/abs/2511.15705)|null|
|**2025-11-20**|**VisPlay: Self-Evolving Vision-Language Models from Images**|Yicheng He et.al.|[2511.15661](http://arxiv.org/abs/2511.15661)|null|
|**2025-11-19**|**When to Think and When to Look: Uncertainty-Guided Lookback**|Jing Bi et.al.|[2511.15613](http://arxiv.org/abs/2511.15613)|null|
|**2025-11-19**|**AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning**|Urjitkumar Patel et.al.|[2511.15578](http://arxiv.org/abs/2511.15578)|null|
|**2025-11-19**|**Two-Faced Social Agents: Context Collapse in Role-Conditioned Large Language Models**|Vikram K Suresh et.al.|[2511.15573](http://arxiv.org/abs/2511.15573)|null|
|**2025-11-19**|**LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering**|Yuanjie Zhu et.al.|[2511.15424](http://arxiv.org/abs/2511.15424)|null|
|**2025-11-19**|**IPR-1: Interactive Physical Reasoner**|Mingyu Zhang et.al.|[2511.15407](http://arxiv.org/abs/2511.15407)|null|
|**2025-11-19**|**DEPO: Dual-Efficiency Preference Optimization for LLM Agents**|Sirui Chen et.al.|[2511.15392](http://arxiv.org/abs/2511.15392)|null|
|**2025-11-19**|**Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models**|Haidong Kang et.al.|[2511.15390](http://arxiv.org/abs/2511.15390)|null|

<p align=right>(<a href=#updated-on-20251121>back to top</a>)</p>

